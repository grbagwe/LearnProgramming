{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oAwV74xD52Wh",
    "outputId": "dc61e4be-55f8-487d-e2bd-19db9e71fa3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gauravb/Documents/Programming/LearnProgramming/LearnPytorch/neural_network\r\n"
     ]
    }
   ],
   "source": [
    "!pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "yM6MbQg354GN"
   },
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "from torchvision import models, datasets, transforms\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rwdkwlls6HaC",
    "outputId": "14178d9e-8401-4e9e-feea-46d53bd5e32a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# downlaod the dataset\n",
    "\n",
    "dataset = datasets.CIFAR10(root='./', train = True, download= True, transform= transforms.ToTensor())\n",
    "train_set, val_set = torch.utils.data.random_split(dataset, [40000, 10000])\n",
    "\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root='./', train = False, download= True, transform= transforms.ToTensor())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "wGl6UWig6fzi"
   },
   "outputs": [],
   "source": [
    "# create the models\n",
    "\n",
    "# model1 = models.AlexNet(num_classes=10)\n",
    "model2 = models.MobileNetV2(num_classes= 100)\n",
    "# model3 = models.resnet18(num_classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0jMoE_Kq-Ado",
    "outputId": "4880639b-d941-486f-ccb9-11d23967abad"
   },
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "# print((model1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1T1gkWkK95DE",
    "outputId": "1d97d68b-eb42-4a7c-f36b-41d6274be6ff"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel2\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model2' is not defined"
     ]
    }
   ],
   "source": [
    "model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4e2aT8ni9B7H",
    "outputId": "879ebaca-b9c8-492c-c911-620b3a2443e5"
   },
   "outputs": [],
   "source": [
    "# model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Bm_E0ueS6uJg"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# train the models\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset= train_set, shuffle= True, batch_size= 256)\n",
    "val_loader = torch.utils.data.DataLoader(dataset= val_set, shuffle= False, batch_size= 16 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "i, l = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32 torch.int64\n",
      "tensor(0.7054, grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "l_oh = F.one_hot(l, num_classes=100)\n",
    "t = model2(i)\n",
    "t_oh = F.sigmoid(t)\n",
    "criterion = nn.BCELoss()\n",
    "print(t_oh.dtype, l_oh.dtype)\n",
    "loss = criterion(t_oh , l_oh.float()) \n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kDYIJJoONKkr",
    "outputId": "7f01c864-f4a6-46ff-af68-c4df394fa765"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 \t\t Training Loss: 0.02445915640592575 \t\t Validation Loss: 0.02375050028860569\n",
      "Validation Loss Decreased(inf--->14.844063) \t Saving The Model\n",
      "Epoch 2 \t\t Training Loss: 0.023303723239898683 \t\t Validation Loss: 0.022755752462148667\n",
      "Validation Loss Decreased(14.844063--->14.222345) \t Saving The Model\n",
      "Epoch 3 \t\t Training Loss: 0.02276343500316143 \t\t Validation Loss: 0.022522259682416917\n",
      "Validation Loss Decreased(14.222345--->14.076412) \t Saving The Model\n",
      "Epoch 4 \t\t Training Loss: 0.021647464063763618 \t\t Validation Loss: 0.022192012412846088\n",
      "Validation Loss Decreased(14.076412--->13.870008) \t Saving The Model\n",
      "Epoch 5 \t\t Training Loss: 0.020934806463122367 \t\t Validation Loss: 0.0211721054404974\n",
      "Validation Loss Decreased(13.870008--->13.232566) \t Saving The Model\n",
      "Epoch 6 \t\t Training Loss: 0.020074984976649283 \t\t Validation Loss: 0.020338151723146437\n",
      "Validation Loss Decreased(13.232566--->12.711345) \t Saving The Model\n",
      "Epoch 7 \t\t Training Loss: 0.01935282330363989 \t\t Validation Loss: 0.02055838891118765\n",
      "Epoch 8 \t\t Training Loss: 0.01880864571481943 \t\t Validation Loss: 0.019206367468833925\n",
      "Validation Loss Decreased(12.711345--->12.003980) \t Saving The Model\n",
      "Epoch 9 \t\t Training Loss: 0.01797748821079731 \t\t Validation Loss: 0.018245662781596183\n",
      "Validation Loss Decreased(12.003980--->11.403539) \t Saving The Model\n",
      "Epoch 10 \t\t Training Loss: 0.017285196423530578 \t\t Validation Loss: 0.017983111004531385\n",
      "Validation Loss Decreased(11.403539--->11.239444) \t Saving The Model\n",
      "Epoch 11 \t\t Training Loss: 0.01698780738413334 \t\t Validation Loss: 0.017846742463111877\n",
      "Validation Loss Decreased(11.239444--->11.154214) \t Saving The Model\n",
      "Epoch 12 \t\t Training Loss: 0.016191481851041318 \t\t Validation Loss: 0.018496183444559573\n",
      "Epoch 13 \t\t Training Loss: 0.01571455796957016 \t\t Validation Loss: 0.016838081139326097\n",
      "Validation Loss Decreased(11.154214--->10.523801) \t Saving The Model\n",
      "Epoch 14 \t\t Training Loss: 0.015042561808228492 \t\t Validation Loss: 0.017477959898859263\n",
      "Epoch 15 \t\t Training Loss: 0.014510760621726513 \t\t Validation Loss: 0.016692728244513275\n",
      "Validation Loss Decreased(10.523801--->10.432955) \t Saving The Model\n",
      "Epoch 16 \t\t Training Loss: 0.01403307820558548 \t\t Validation Loss: 0.016174520643800497\n",
      "Validation Loss Decreased(10.432955--->10.109075) \t Saving The Model\n",
      "Epoch 17 \t\t Training Loss: 0.013553900022804738 \t\t Validation Loss: 0.01666527716591954\n",
      "Epoch 18 \t\t Training Loss: 0.013249805274605751 \t\t Validation Loss: 0.016625166514515878\n",
      "Epoch 19 \t\t Training Loss: 0.012722026730328798 \t\t Validation Loss: 0.016279559501260518\n",
      "Epoch 20 \t\t Training Loss: 0.012223281940072776 \t\t Validation Loss: 0.015985408145561816\n",
      "Validation Loss Decreased(10.109075--->9.990880) \t Saving The Model\n",
      "Epoch 21 \t\t Training Loss: 0.011974932107329368 \t\t Validation Loss: 0.016623974337428807\n",
      "Epoch 22 \t\t Training Loss: 0.011537194745242596 \t\t Validation Loss: 0.016394262810051442\n",
      "Epoch 23 \t\t Training Loss: 0.010948864045739174 \t\t Validation Loss: 0.017046251860260965\n",
      "Epoch 24 \t\t Training Loss: 0.010687847813218833 \t\t Validation Loss: 0.01675294462516904\n",
      "Epoch 25 \t\t Training Loss: 0.010378707541525364 \t\t Validation Loss: 0.016256517369300127\n",
      "Epoch 26 \t\t Training Loss: 0.010024084341526032 \t\t Validation Loss: 0.015644626377522945\n",
      "Validation Loss Decreased(9.990880--->9.777891) \t Saving The Model\n",
      "Epoch 27 \t\t Training Loss: 0.00944625492990017 \t\t Validation Loss: 0.016635462792217733\n",
      "Epoch 28 \t\t Training Loss: 0.009214681390672922 \t\t Validation Loss: 0.0159905732255429\n",
      "Epoch 29 \t\t Training Loss: 0.008803931598737836 \t\t Validation Loss: 0.016868866762891413\n",
      "Epoch 30 \t\t Training Loss: 0.00860031821615994 \t\t Validation Loss: 0.016741323493421077\n",
      "Epoch 31 \t\t Training Loss: 0.008188139725103974 \t\t Validation Loss: 0.016693225737847386\n",
      "Epoch 32 \t\t Training Loss: 0.007901936389505863 \t\t Validation Loss: 0.016642581511288883\n",
      "Epoch 33 \t\t Training Loss: 0.00753426431119442 \t\t Validation Loss: 0.017531743667833506\n",
      "Epoch 34 \t\t Training Loss: 0.007455676647648215 \t\t Validation Loss: 0.01872851153817028\n",
      "Epoch 35 \t\t Training Loss: 0.006933255745843053 \t\t Validation Loss: 0.01902834595181048\n",
      "Epoch 36 \t\t Training Loss: 0.006729363956674933 \t\t Validation Loss: 0.01760421578362584\n",
      "Epoch 37 \t\t Training Loss: 0.006460439466312528 \t\t Validation Loss: 0.017520591014809905\n",
      "Epoch 38 \t\t Training Loss: 0.006177028738334775 \t\t Validation Loss: 0.016975051490962505\n",
      "Epoch 39 \t\t Training Loss: 0.005951495670154691 \t\t Validation Loss: 0.018560753362439574\n",
      "Epoch 40 \t\t Training Loss: 0.005805672633089125 \t\t Validation Loss: 0.01840280987555161\n",
      "Epoch 41 \t\t Training Loss: 0.005608557417988777 \t\t Validation Loss: 0.017648936006613075\n",
      "Epoch 42 \t\t Training Loss: 0.005304874777980148 \t\t Validation Loss: 0.01954150433316827\n",
      "Epoch 43 \t\t Training Loss: 0.005155470061488449 \t\t Validation Loss: 0.01959151628650725\n",
      "Epoch 44 \t\t Training Loss: 0.004836619144305587 \t\t Validation Loss: 0.0191327244611457\n",
      "Epoch 45 \t\t Training Loss: 0.004739836543332786 \t\t Validation Loss: 0.01887729951031506\n",
      "Epoch 46 \t\t Training Loss: 0.0045988398939371105 \t\t Validation Loss: 0.0191477661148645\n",
      "Epoch 47 \t\t Training Loss: 0.004258305334299803 \t\t Validation Loss: 0.020821475460077635\n",
      "Epoch 48 \t\t Training Loss: 0.004314933592639863 \t\t Validation Loss: 0.020694249897822738\n",
      "Epoch 49 \t\t Training Loss: 0.004149838155135512 \t\t Validation Loss: 0.020183706385828556\n",
      "Epoch 50 \t\t Training Loss: 0.0038787352559156714 \t\t Validation Loss: 0.023157756526209414\n",
      "Epoch 51 \t\t Training Loss: 0.0038577492812648414 \t\t Validation Loss: 0.021701486382819712\n",
      "Epoch 52 \t\t Training Loss: 0.0036841147581581028 \t\t Validation Loss: 0.020656055581010878\n",
      "Epoch 53 \t\t Training Loss: 0.003504149822983891 \t\t Validation Loss: 0.021596936329174785\n",
      "Epoch 54 \t\t Training Loss: 0.0033873464532662182 \t\t Validation Loss: 0.022166164419893174\n",
      "Epoch 55 \t\t Training Loss: 0.0033393291155342014 \t\t Validation Loss: 0.02111317552290857\n",
      "Epoch 56 \t\t Training Loss: 0.003160353400791064 \t\t Validation Loss: 0.02180729883648455\n",
      "Epoch 57 \t\t Training Loss: 0.003176502177119255 \t\t Validation Loss: 0.02248992681372911\n",
      "Epoch 58 \t\t Training Loss: 0.003004263388924301 \t\t Validation Loss: 0.022684700489183886\n",
      "Epoch 59 \t\t Training Loss: 0.002919765295786783 \t\t Validation Loss: 0.022993012722209095\n",
      "Epoch 60 \t\t Training Loss: 0.0027007235455093906 \t\t Validation Loss: 0.02453844231031835\n",
      "Epoch 61 \t\t Training Loss: 0.002701078704977408 \t\t Validation Loss: 0.022854065358079968\n",
      "Epoch 62 \t\t Training Loss: 0.0027618801541160793 \t\t Validation Loss: 0.022235902823880316\n",
      "Epoch 63 \t\t Training Loss: 0.002542662927438505 \t\t Validation Loss: 0.023228242890164254\n",
      "Epoch 64 \t\t Training Loss: 0.0025006400663638486 \t\t Validation Loss: 0.02264616839545779\n",
      "Epoch 65 \t\t Training Loss: 0.0024469565460458398 \t\t Validation Loss: 0.0244995485028252\n",
      "Epoch 66 \t\t Training Loss: 0.0024251148705603555 \t\t Validation Loss: 0.023176096436940134\n",
      "Epoch 67 \t\t Training Loss: 0.0023378785333829 \t\t Validation Loss: 0.02465837114751339\n",
      "Epoch 68 \t\t Training Loss: 0.0022108537863008678 \t\t Validation Loss: 0.023743048995733262\n",
      "Epoch 69 \t\t Training Loss: 0.002256428383779712 \t\t Validation Loss: 0.024273045236058534\n",
      "Epoch 70 \t\t Training Loss: 0.0021076775442343204 \t\t Validation Loss: 0.02462846813518554\n",
      "Epoch 71 \t\t Training Loss: 0.0020649006641004232 \t\t Validation Loss: 0.024955214733444156\n",
      "Epoch 72 \t\t Training Loss: 0.0021262868868536316 \t\t Validation Loss: 0.022828574786894023\n",
      "Epoch 73 \t\t Training Loss: 0.0020126200658967717 \t\t Validation Loss: 0.024864974917843938\n",
      "Epoch 74 \t\t Training Loss: 0.002009770006965846 \t\t Validation Loss: 0.02595743171251379\n",
      "Epoch 75 \t\t Training Loss: 0.0018878932093502954 \t\t Validation Loss: 0.024944507368514314\n",
      "Epoch 76 \t\t Training Loss: 0.0019664496900397353 \t\t Validation Loss: 0.02553429100718349\n",
      "Epoch 77 \t\t Training Loss: 0.0017742968581384048 \t\t Validation Loss: 0.02570532150864601\n",
      "Epoch 78 \t\t Training Loss: 0.0018435686287470161 \t\t Validation Loss: 0.025218627709150315\n",
      "Epoch 79 \t\t Training Loss: 0.0017796080525033177 \t\t Validation Loss: 0.025979171329177916\n",
      "Epoch 80 \t\t Training Loss: 0.0017489097664598375 \t\t Validation Loss: 0.02632628446504241\n",
      "Epoch 81 \t\t Training Loss: 0.0016165400127472823 \t\t Validation Loss: 0.02589856382403523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 \t\t Training Loss: 0.0016548765744431875 \t\t Validation Loss: 0.0281451301838737\n",
      "Epoch 83 \t\t Training Loss: 0.0016655825100606308 \t\t Validation Loss: 0.027011270352173596\n",
      "Epoch 84 \t\t Training Loss: 0.0016545965030207298 \t\t Validation Loss: 0.02581915003506001\n",
      "Epoch 85 \t\t Training Loss: 0.0015163936614524573 \t\t Validation Loss: 0.02564832084896043\n",
      "Epoch 86 \t\t Training Loss: 0.0015237743374425918 \t\t Validation Loss: 0.026906563699012623\n",
      "Epoch 87 \t\t Training Loss: 0.0015797294104704634 \t\t Validation Loss: 0.02625770761311287\n",
      "Epoch 88 \t\t Training Loss: 0.0014595443139667622 \t\t Validation Loss: 0.027020867410488425\n",
      "Epoch 89 \t\t Training Loss: 0.0014645804045023397 \t\t Validation Loss: 0.024150219351798296\n",
      "Epoch 90 \t\t Training Loss: 0.0014445632133167237 \t\t Validation Loss: 0.027381890665879472\n",
      "Epoch 91 \t\t Training Loss: 0.0013339855210564564 \t\t Validation Loss: 0.029488011711509898\n",
      "Epoch 92 \t\t Training Loss: 0.0015276394654763863 \t\t Validation Loss: 0.024815599236823617\n",
      "Epoch 93 \t\t Training Loss: 0.001423852259013802 \t\t Validation Loss: 0.02545097479415126\n",
      "Epoch 94 \t\t Training Loss: 0.001343312377203256 \t\t Validation Loss: 0.02677074665799737\n",
      "Epoch 95 \t\t Training Loss: 0.0012803685756225605 \t\t Validation Loss: 0.026927223529061302\n",
      "Epoch 96 \t\t Training Loss: 0.0013020232690440026 \t\t Validation Loss: 0.02731268002828583\n",
      "Epoch 97 \t\t Training Loss: 0.0013295514882309361 \t\t Validation Loss: 0.029813531467108988\n",
      "Epoch 98 \t\t Training Loss: 0.0013070317339152098 \t\t Validation Loss: 0.02852036015818594\n",
      "Epoch 99 \t\t Training Loss: 0.001258358941419283 \t\t Validation Loss: 0.02579327882118523\n",
      "Epoch 100 \t\t Training Loss: 0.0012956168100237847 \t\t Validation Loss: 0.026125143067725003\n"
     ]
    }
   ],
   "source": [
    "# train the model \n",
    "import numpy as np \n",
    "\n",
    "# create a loss function\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "\n",
    "# create an optimzer\n",
    "optimizer = torch.optim.Adam(model2.parameters(), lr= 0.001)\n",
    "num_epochs  = 100\n",
    "min_valid_loss = np.inf\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# device = 'cpu'\n",
    "model2.to(device)\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0\n",
    "    model2.train()\n",
    "    for batch_idx,(images, labels) in enumerate(train_loader):\n",
    "    # forward pass\n",
    "        images = images.to(device)\n",
    "        labels = F.one_hot(labels, num_classes=100)\n",
    "\n",
    "\n",
    "        labels = labels.to(device)\n",
    "        outputs  = model2(images)\n",
    "        outputs = F.sigmoid(outputs)\n",
    "\n",
    "\n",
    "        # find the loss\n",
    "        loss = criterion(outputs, labels.float())\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # back propogate the loss\n",
    "\n",
    "          # Clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "              # Update Weights\n",
    "        optimizer.step()\n",
    "        #     if batch_idx // 100  == 0 :\n",
    "        #       print(f'Epoch {epoch +1} \\t\\t Training Loss: {train_loss / len(train_loader)} ')\n",
    "\n",
    "        # validation\n",
    "        valid_loss = 0.0\n",
    "        model2.eval()     # Optional when not using Model Specific layer\n",
    "    for data, labels in val_loader:\n",
    "        # Transfer Data to GPU if available\n",
    "        labels = F.one_hot(labels, num_classes=100)\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "        # Forward Pass\n",
    "        target = model2(data)\n",
    "        outputs = F.sigmoid(target)\n",
    "        # Find the Loss\n",
    "        loss = criterion(outputs, labels.float())\n",
    "\n",
    "        # Calculate Loss\n",
    "        valid_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch +1} \\t\\t Training Loss: {train_loss / len(train_loader)} \\t\\t Validation Loss: {valid_loss / len(val_loader)}')\n",
    "\n",
    "    if min_valid_loss > valid_loss:\n",
    "      print(f'Validation Loss Decreased({min_valid_loss:.6f}--->{valid_loss:.6f}) \\t Saving The Model')\n",
    "      min_valid_loss = valid_loss\n",
    "\n",
    "      # Saving State Dict\n",
    "      torch.save(model2.state_dict(), 'saved_model.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D7cp_CHaBFhr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:LearnPytorch]",
   "language": "python",
   "name": "conda-env-LearnPytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
