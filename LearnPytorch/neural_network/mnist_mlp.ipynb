{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from torchsummary import summary\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mnist dataset\n",
    "transform = torchvision.transforms.ToTensor()\n",
    "train = torchvision.datasets.MNIST(root='../datasets/', download = True, train= True, transform = transform)\n",
    "test  = torchvision.datasets.MNIST(root='../datasets/', download = True, train= False, transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(dataset=train,batch_size=50,shuffle = True)\n",
    "test_dataloader = torch.utils.data.DataLoader(dataset=test,batch_size=50,shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1, 28, 28])\n",
      "torch.Size([50])\n"
     ]
    }
   ],
   "source": [
    "# shape of each batch\n",
    "print(next(iter(train_dataloader))[0].shape)\n",
    "#labels\n",
    "print(next(iter(train_dataloader))[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a neural network\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "class MLP_network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP_network, self).__init__()\n",
    "        # input size\n",
    "        self.fc1 = nn.Linear(28*28, 500)\n",
    "        # next layer\n",
    "        self.fc2 = nn.Linear(500, 256)\n",
    "        self.fc3 = nn.Linear(256, 256)\n",
    "        self.fc4 = nn.Linear(256, 64)\n",
    "        # output layer\n",
    "        self.fc5 = nn.Linear(64, 10)\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.fc5(x) # output\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP_network(\n",
       "  (fc1): Linear(in_features=784, out_features=500, bias=True)\n",
       "  (fc2): Linear(in_features=500, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (fc4): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (fc5): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLP_network()\n",
    "device = 'cuda'\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603646\n",
      " total parameters counted  second layer 128256\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                  [-1, 500]         392,500\n",
      "            Linear-2                  [-1, 256]         128,256\n",
      "            Linear-3                  [-1, 256]          65,792\n",
      "            Linear-4                  [-1, 256]          65,792\n",
      "            Linear-5                   [-1, 64]          16,448\n",
      "            Linear-6                   [-1, 10]             650\n",
      "================================================================\n",
      "Total params: 669,438\n",
      "Trainable params: 669,438\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 2.55\n",
      "Estimated Total Size (MB): 2.57\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# print total learnable parameters\n",
    "total_params = sum(p.numel() for p in model.parameters() )\n",
    "print(total_params)\n",
    "print(\" total parameters counted  second layer\", (256) * 500 + 256 )\n",
    "summary(model,(1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss().to(device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gauravb/miniconda3/envs/LearnPytorch/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/gauravb/miniconda3/envs/LearnPytorch/lib/python3.10/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "==>>>  batch index: 100, acc: 0.975\n",
      "==>>>  batch index: 200, acc: 0.982\n",
      "nan\n",
      "==>>>  batch index: 100, acc: 0.970\n",
      "==>>>  batch index: 200, acc: 0.979\n",
      "nan\n",
      "==>>>  batch index: 100, acc: 0.971\n",
      "==>>>  batch index: 200, acc: 0.980\n",
      "nan\n",
      "==>>>  batch index: 100, acc: 0.973\n",
      "==>>>  batch index: 200, acc: 0.982\n",
      "nan\n",
      "==>>>  batch index: 100, acc: 0.972\n",
      "==>>>  batch index: 200, acc: 0.979\n",
      "nan\n",
      "==>>>  batch index: 100, acc: 0.975\n",
      "==>>>  batch index: 200, acc: 0.983\n",
      "nan\n",
      "==>>>  batch index: 100, acc: 0.977\n",
      "==>>>  batch index: 200, acc: 0.984\n",
      "nan\n",
      "==>>>  batch index: 100, acc: 0.977\n",
      "==>>>  batch index: 200, acc: 0.984\n",
      "nan\n",
      "==>>>  batch index: 100, acc: 0.978\n",
      "==>>>  batch index: 200, acc: 0.984\n",
      "nan\n",
      "==>>>  batch index: 100, acc: 0.980\n",
      "==>>>  batch index: 200, acc: 0.986\n",
      "nan\n",
      "==>>>  batch index: 100, acc: 0.979\n",
      "==>>>  batch index: 200, acc: 0.985\n",
      "nan\n",
      "==>>>  batch index: 100, acc: 0.979\n",
      "==>>>  batch index: 200, acc: 0.984\n",
      "nan\n",
      "==>>>  batch index: 100, acc: 0.979\n",
      "==>>>  batch index: 200, acc: 0.984\n",
      "nan\n",
      "==>>>  batch index: 100, acc: 0.976\n",
      "==>>>  batch index: 200, acc: 0.984\n",
      "nan\n",
      "==>>>  batch index: 100, acc: 0.975\n",
      "==>>>  batch index: 200, acc: 0.982\n",
      "nan\n",
      "==>>>  batch index: 100, acc: 0.967\n",
      "==>>>  batch index: 200, acc: 0.976\n",
      "nan\n",
      "==>>>  batch index: 100, acc: 0.979\n",
      "==>>>  batch index: 200, acc: 0.985\n",
      "nan\n",
      "==>>>  batch index: 100, acc: 0.980\n",
      "==>>>  batch index: 200, acc: 0.986\n",
      "nan\n",
      "==>>>  batch index: 100, acc: 0.977\n",
      "==>>>  batch index: 200, acc: 0.983\n",
      "nan\n",
      "==>>>  batch index: 100, acc: 0.976\n",
      "==>>>  batch index: 200, acc: 0.982\n"
     ]
    }
   ],
   "source": [
    "# loop over the epochs\n",
    "for  i in range(0, 20):\n",
    "    avgloss = []\n",
    "    for batch,(images, labels) in enumerate(train_dataloader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        \n",
    "#         print(outputs[0], labels[0])\n",
    "#         print((outputs[0]))\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(np.mean(avgloss))\n",
    "        # testing\n",
    "    correct_cnt, ave_loss = 0, 0\n",
    "    total_cnt = 0\n",
    "    for batch_idx, (x, target) in enumerate(test_dataloader):\n",
    "        if device:\n",
    "            x, target = x.cuda(), target.cuda()\n",
    "    #     x, target = Variable(x, volatile=True), Variable(target, volatile=True)\n",
    "        out = model(x)\n",
    "        loss = criterion(out, target)\n",
    "        _, pred_label = torch.max(out.data, 1)\n",
    "        total_cnt += x.data.size()[0]\n",
    "        correct_cnt += (pred_label == target.data).sum()\n",
    "        # smooth average\n",
    "    #     ave_loss = ave_loss * 0.9 + loss.data[0] * 0.1\n",
    "\n",
    "        if(batch_idx+1) % 100 == 0 or (batch_idx+1) == len(test_dataloader):\n",
    "            print( '==>>>  batch index: {}, acc: {:.3f}'.format(\n",
    "                 batch_idx+1, correct_cnt * 1.0 / total_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "correct_cnt, ave_loss = 0, 0\n",
    "total_cnt = 0\n",
    "for batch_idx, (x, target) in enumerate(test_dataloader):\n",
    "    if device:\n",
    "        x, target = x.cuda(), target.cuda()\n",
    "#     x, target = Variable(x, volatile=True), Variable(target, volatile=True)\n",
    "    out = model(x)\n",
    "    loss = criterion(out, target)\n",
    "    _, pred_label = torch.max(out.data, 1)\n",
    "    total_cnt += x.data.size()[0]\n",
    "    correct_cnt += (pred_label == target.data).sum()\n",
    "    # smooth average\n",
    "#     ave_loss = ave_loss * 0.9 + loss.data[0] * 0.1\n",
    "\n",
    "    if(batch_idx+1) % 100 == 0 or (batch_idx+1) == len(test_dataloader):\n",
    "        print( '==>>>  batch index: {}, acc: {:.3f}'.format(\n",
    "             batch_idx+1, correct_cnt * 1.0 / total_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
